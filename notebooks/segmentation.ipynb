{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "# pip install torchsummary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    def __init__(self):\n",
    "        self.img_size = 128 # org size mean 575 x 766\n",
    "        self.batch_size = 6 #6\n",
    "        self.seed = 42\n",
    "        self.workers = 3 #3\n",
    "        self.lr = 0.001\n",
    "config = config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhC(torch.utils.data.Dataset):\n",
    "    def __init__(self,transform):\n",
    "        'Initialization'\n",
    "        self.transform = transform\n",
    "        self.data_path = \"/dtu/datasets1/02516/PH2_Dataset_images\"\n",
    "        self.image_paths = sorted(glob.glob(f\"{self.data_path}/*/*_Dermoscopic_Image/*.bmp\"))\n",
    "        self.label_paths = sorted(glob.glob(f\"{self.data_path}/*/*_lesion/*_lesion.bmp\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        'Generates one sample of data'\n",
    "        image_path = self.image_paths[idx]\n",
    "        label_path = self.label_paths[idx]\n",
    "        image = Image.open(image_path)\n",
    "        label = Image.open(label_path)\n",
    "        Y = self.transform(label)\n",
    "        X = self.transform(image)\n",
    "\n",
    "        return X, Y\n",
    "    \n",
    "\n",
    "size = config.img_size\n",
    "train_transform = transforms.Compose([transforms.Resize((size, size)), \n",
    "                                    transforms.ToTensor()])\n",
    "test_transform = transforms.Compose([transforms.Resize((size, size)), \n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "trainset = PhC(transform=train_transform)\n",
    "trainset, val_test_set = torch.utils.data.random_split(trainset, [120, 80],generator=torch.Generator().manual_seed(config.seed))\n",
    "valset, testset = torch.utils.data.random_split(val_test_set, [40, 40],generator=torch.Generator().manual_seed(config.seed))\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=config.batch_size, shuffle=True, num_workers=config.workers,generator=torch.Generator().manual_seed(config.seed))\n",
    "val_loader = DataLoader(valset, batch_size=config.batch_size, shuffle=False, num_workers=config.workers,generator=torch.Generator().manual_seed(config.seed))\n",
    "test_loader = DataLoader(testset, batch_size=config.batch_size, shuffle=False, num_workers=config.workers,generator=torch.Generator().manual_seed(config.seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EncDec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncDec(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder-Decoder network for image segmentation.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Attributes:\n",
    "        enc_conv0 (nn.Conv2d): Convolutional layer for the first encoder block.\n",
    "        pool0 (nn.MaxPool2d): Max pooling layer for downsampling.\n",
    "        enc_conv1 (nn.Conv2d): Convolutional layer for the second encoder block.\n",
    "        pool1 (nn.MaxPool2d): Max pooling layer for downsampling.\n",
    "        enc_conv2 (nn.Conv2d): Convolutional layer for the third encoder block.\n",
    "        pool2 (nn.MaxPool2d): Max pooling layer for downsampling.\n",
    "        enc_conv3 (nn.Conv2d): Convolutional layer for the fourth encoder block.\n",
    "        pool3 (nn.MaxPool2d): Max pooling layer for downsampling.\n",
    "        bottleneck_conv (nn.Conv2d): Convolutional layer for the bottleneck block.\n",
    "        upsample0 (nn.Upsample): Upsampling layer for the first decoder block.\n",
    "        dec_conv0 (nn.Conv2d): Convolutional layer for the first decoder block.\n",
    "        upsample1 (nn.Upsample): Upsampling layer for the second decoder block.\n",
    "        dec_conv1 (nn.Conv2d): Convolutional layer for the second decoder block.\n",
    "        upsample2 (nn.Upsample): Upsampling layer for the third decoder block.\n",
    "        dec_conv2 (nn.Conv2d): Convolutional layer for the third decoder block.\n",
    "        upsample3 (nn.Upsample): Upsampling layer for the fourth decoder block.\n",
    "        dec_conv3 (nn.Conv2d): Convolutional layer for the final decoder block.\n",
    "\n",
    "    Methods:\n",
    "        forward(x): Performs forward pass through the network.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        inp_size = config.img_size//2\n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, inp_size, 3, padding=1)\n",
    "        self.pool0 = nn.MaxPool2d(2, 2)  # 128 -> 64\n",
    "        self.enc_conv1 = nn.Conv2d(inp_size, inp_size, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 64 -> 32\n",
    "        self.enc_conv2 = nn.Conv2d(inp_size, inp_size, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 32 -> 16\n",
    "        self.enc_conv3 = nn.Conv2d(inp_size, inp_size, 3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # 16 -> 8\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv = nn.Conv2d(inp_size, inp_size, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.Upsample(scale_factor=2)  # 8 -> 16\n",
    "        self.dec_conv0 = nn.Conv2d(inp_size, inp_size, 3, padding=1)\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)  # 16 -> 32\n",
    "        self.dec_conv1 = nn.Conv2d(inp_size, inp_size, 3, padding=1)\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)  # 32 -> 64\n",
    "        self.dec_conv2 = nn.Conv2d(inp_size, inp_size, 3, padding=1)\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2)  # 64 -> 128\n",
    "        self.dec_conv3 = nn.Conv2d(inp_size, 1, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        e0 = self.pool0(F.relu(self.enc_conv0(x)))\n",
    "        e1 = self.pool1(F.relu(self.enc_conv1(e0)))\n",
    "        e2 = self.pool2(F.relu(self.enc_conv2(e1)))\n",
    "        e3 = self.pool3(F.relu(self.enc_conv3(e2)))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.relu(self.bottleneck_conv(e3))\n",
    "\n",
    "        # decoder\n",
    "        d0 = F.relu(self.dec_conv0(self.upsample0(b)))\n",
    "        d1 = F.relu(self.dec_conv1(self.upsample1(d0)))\n",
    "        d2 = F.relu(self.dec_conv2(self.upsample2(d1)))\n",
    "        d3 = self.dec_conv3(self.upsample3(d2))  # no activation\n",
    "        return d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GeneralUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self, in_ch:int=3, out_ch:int=1,upsample_type='transpose'):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.factor = 2 if upsample_type == 'bilinear' else 1\n",
    "\n",
    "        self.d1 = create_block(in_channels=in_ch,out_channels=64,padding=1)\n",
    "        self.d2 = create_block(in_channels=64,out_channels=128,padding=1)\n",
    "        self.d3 = create_block(in_channels=128,out_channels=256,padding=1)\n",
    "        self.d4 = create_block(in_channels=256,out_channels=512,padding=1)\n",
    "        self.bottleneck = create_block(in_channels=512,out_channels=1024//self.factor,padding=1)\n",
    "\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.u1_conv = create_block(in_channels=1024,out_channels=512//self.factor,padding=1)\n",
    "        self.u2_conv = create_block(in_channels=512,out_channels=256//self.factor,padding=1)\n",
    "        self.u3_conv = create_block(in_channels=256,out_channels=128//self.factor,padding=1)\n",
    "        self.u4_conv = create_block(in_channels=128,out_channels=64,padding=1)\n",
    "\n",
    "        if upsample_type == 'transpose':\n",
    "            self.u1 = nn.ConvTranspose2d(1024, 512//self.factor, kernel_size=2, stride=2)\n",
    "            self.u2 = nn.ConvTranspose2d(512, 256//self.factor, kernel_size=2, stride=2)\n",
    "            self.u3 = nn.ConvTranspose2d(256, 128//self.factor, kernel_size=2, stride=2)\n",
    "            self.u4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        elif upsample_type == 'bilinear':\n",
    "            self.u1 = nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "            self.u2 = nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "            self.u3 = nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "            self.u4 = nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "\n",
    "        self.out = nn.Conv2d(64, out_ch, kernel_size=1)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        down1 = self.d1(x) \n",
    "        x = self.maxpool(down1)  \n",
    "\n",
    "        down2 = self.d2(x)  \n",
    "        x = self.maxpool(down2) \n",
    "        x=self.dropout(x)\n",
    "\n",
    "        down3 = self.d3(x)  \n",
    "        x = self.maxpool(down3)\n",
    "        x=self.dropout(x)  \n",
    "\n",
    "        down4 = self.d4(x)  \n",
    "        x = self.maxpool(down4)\n",
    "        x=self.dropout(x)  \n",
    "\n",
    "        bottleneck = self.bottleneck(x) \n",
    "\n",
    "        # Decoder\n",
    "        up1 = self.u1(bottleneck) \n",
    "        x = torch.cat([up1, down4], dim=1)  \n",
    "        x = self.u1_conv(x)\n",
    "        x=self.dropout(x)  \n",
    "\n",
    "        up2 = self.u2(x) \n",
    "        x = torch.cat([up2, down3], dim=1)  \n",
    "        x = self.u2_conv(x)\n",
    "        x=self.dropout(x)  \n",
    "\n",
    "        up3 = self.u3(x)  \n",
    "        x = torch.cat([up3, down2], dim=1)  \n",
    "        x = self.u3_conv(x)\n",
    "        x=self.dropout(x) \n",
    "\n",
    "        up4 = self.u4(x) \n",
    "        x = torch.cat([up4, down1], dim=1)  \n",
    "        x = self.u4_conv(x) \n",
    "\n",
    "        # #output layer\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class metrics:\n",
    "    def __init__(self,eps:float=1e-8):\n",
    "        self.eps = eps\n",
    "\n",
    "    def get_confusion(self,y_hat,mask):\n",
    "        # assuming y_hat is logits, then convert to confidences using sigmoid\n",
    "        if y_hat.min().item() < 0.0 or (y_hat.max().item() > 1.0):\n",
    "            y_hat = torch.sigmoid(y_hat)\n",
    "        y_hat = (y_hat > 0.50).float()\n",
    "\n",
    "        self.TP = (y_hat.flatten() * mask.flatten()).sum()\n",
    "        self.FN = mask[y_hat == 0].sum()\n",
    "        self.FP = y_hat[mask == 0].sum()\n",
    "        self.TN = y_hat.numel() - self.TP - self.FN - self.FP\n",
    "\n",
    "    def get_metrics(self,y_hat,mask):\n",
    "        self.get_confusion(y_hat,mask)\n",
    "        dice = ((2 * self.TP) / (2 * self.TP + self.FN + self.FP + self.eps)).item()\n",
    "        iou = ((self.TP) / (self.TP + self.FN + self.FP )).item()\n",
    "        acc = (self.TP+self.TN)/(self.TP+self.TN+self.FP+self.FN)\n",
    "        sensitivity = self.TP/(self.TP+self.FN)\n",
    "        specificity = self.TN/(self.TN+self.FP)\n",
    "        self.metric_dict = {'dice':dice,'iou':iou,'acc':acc,'sensitivity':sensitivity,'specificity':specificity}\n",
    "        return self.metric_dict \n",
    "    \n",
    "    def print_my_metrics(self,y_hat,mask,type_):\n",
    "        metric_dict = self.get_metrics(y_hat,mask)\n",
    "        for key in metric_dict:\n",
    "            print(f\"{type_} {key}: {metric_dict[key]}\")\n",
    "    \n",
    "evaluator = metrics() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss_func:\n",
    "    def __init__(self,type_:str='BCE'):\n",
    "        self.type_ = type_\n",
    "        self.gamma = 2\n",
    "        self.pos_weights = torch.tensor(2) # approx\n",
    "\n",
    "    def BCE(self):\n",
    "        return torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def FocalLoss(self,y_hat,mask):\n",
    "        y_hat = torch.sigmoid(y_hat)\n",
    "        return - torch.mean((1-y_hat)**self.gamma  * mask * torch.log(y_hat) + (1-mask)*torch.log(1-y_hat))\n",
    "\n",
    "    def WeightedBCE(self):\n",
    "        return torch.nn.BCEWithLogitsLoss(pos_weight=self.pos_weights)\n",
    "    \n",
    "    def get_loss(self,y_hat,mask):\n",
    "        if self.type_ == 'BCE':\n",
    "            return self.BCE()(y_hat,mask)\n",
    "        elif self.type_ == 'FocalLoss':\n",
    "            return self.FocalLoss(y_hat,mask)\n",
    "        elif self.type_ == 'WeightedBCE':\n",
    "            return self.WeightedBCE()(y_hat,mask)\n",
    "    \n",
    "    def loss_name(self):\n",
    "        return self.type_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, criterion, epochs, train_loader, val_loader, test_loader,save_text=None):\n",
    "    X_val, Y_val = next(iter(val_loader))\n",
    "    X_test,Y_test = next(iter(test_loader))\n",
    "\n",
    "    best_val_dice = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        model.train()  # train mode\n",
    "\n",
    "        trains_dice = 0\n",
    "        train_acc = 0\n",
    "        trains_iou = 0\n",
    "        train_sensitivity = 0\n",
    "        train_specificity = 0\n",
    "        for X_batch, Y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "\n",
    "            # set parameter gradients to zero\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            Y_pred = model(X_batch)\n",
    "            loss = criterion.get_loss(Y_pred,Y_batch)  # forward-pass\n",
    "            loss.backward()  # backward-pass\n",
    "            opt.step()  # update weights\n",
    "\n",
    "            train_metrics = evaluator.get_metrics(F.sigmoid(Y_pred),Y_batch)\n",
    "\n",
    "            # calculate metrics to show the user\n",
    "            avg_loss += loss / len(train_loader)\n",
    "            train_dice += train_metrics['dice']/ len(train_loader)\n",
    "            train_acc += train_metrics['acc']/ len(train_loader)\n",
    "            trains_iou += train_metrics['iou']/ len(train_loader)\n",
    "            train_sensitivity += train_metrics['sensitivity']/ len(train_loader)\n",
    "            train_specificity += train_metrics['specificity']/ len(train_loader)\n",
    "\n",
    "        train_final_metrics = {'loss':avg_loss,'acc':train_acc,'dice':train_dice,'iou':trains_iou,'sensitivity':train_sensitivity,'specificity':train_specificity}\n",
    "        toc = time()\n",
    "        print(' - loss: %f' % avg_loss)\n",
    "\n",
    "\n",
    "        # show intermediate results\n",
    "        model.eval()  # testing mode\n",
    "\n",
    "        val_dice = 0\n",
    "        val_acc = 0\n",
    "        val_iou = 0\n",
    "        val_sensitivity = 0\n",
    "        val_specificity = 0\n",
    "        val_avg_loss=0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, Y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                Y_batch = Y_batch.to(device)\n",
    "                Y_pred = model(X_batch)\n",
    "                loss = criterion.get_loss(Y_pred,Y_batch)\n",
    "                val_avg_loss += loss / len(val_loader)\n",
    "                val_metrics = evaluator.get_metrics(F.sigmoid(Y_pred),Y_batch)\n",
    "                val_dice += val_metrics['dice']/ len(val_loader)\n",
    "                val_acc += val_metrics['acc']/ len(val_loader)\n",
    "                val_iou += val_metrics['iou']/ len(val_loader)\n",
    "                val_sensitivity += val_metrics['sensitivity']/ len(val_loader)\n",
    "                val_specificity += val_metrics['specificity']/ len(val_loader)\n",
    "\n",
    "        val_final_metrics = {'loss':val_avg_loss,'acc':val_acc,'dice':val_dice,'iou':val_iou,'sensitivity':val_sensitivity,'specificity':val_specificity}\n",
    "\n",
    "        if val_dice >best_val_dice:\n",
    "            best_val_dice = val_dice\n",
    "            best_model_path = f\"best_model.pth\"\n",
    "            torch.save(model.state_dict(),best_model_path)\n",
    "            best_val_final_metrics = val_final_metrics\n",
    "            best_train_final_metrics = train_final_metrics\n",
    "\n",
    "        Y_hat = F.sigmoid(model(X_val.to(device))).detach().cpu()\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(nrows=4, ncols=6, figsize=(8.5, 5),dpi=400)\n",
    "        for k in range(6):\n",
    "            im = np.rollaxis(X_val[k].numpy(), 0, 3)\n",
    "            cmap = 'jet'\n",
    "            ax[0,k].imshow(im)\n",
    "            ax[1,k].imshow(Y_val[k, 0], cmap=cmap)\n",
    "            ax[2,k].imshow(Y_hat[k, 0], cmap=cmap,vmin=0, vmax=1)\n",
    "            thres = 0.5\n",
    "            maskim = im.copy()\n",
    "            maskim[Y_hat[k][0]<=thres] = [0,0,0]\n",
    "            implt = ax[3,k].imshow(maskim, cmap=cmap,vmin=0, vmax=1)\n",
    "        titles = ['Real','Mask','Output','Threshold']\n",
    "        for i in range(4): \n",
    "            ax[i,0].text(-0.1, 0.5, titles[i],rotation=90,ha='center',va='center',transform=ax[i,0].transAxes)\n",
    "        for a in ax.flat: \n",
    "            a.set_axis_off()\n",
    "        #metricstxt = 'dice: {:.2f} iou: {:.2f} acc: {:.2f} sens: {:.2f} spec: {:.2f}'.format(val_dice,val_iou,val_acc,val_sensitivity,val_specificity)\n",
    "        #ax[0,0].text(0, 1.25, metricstxt,ha='left',va='center',transform=ax[0,0].transAxes)\n",
    "        plt.suptitle(f\"Validation\")\n",
    "        metricstxt = f'Epoch {epoch+1} / {epochs}    loss: {val_avg_loss:.2f}'\n",
    "        cbar = fig.colorbar(implt, ax=ax.ravel().tolist(), shrink=0.97)\n",
    "        cbar.set_ticks([0,thres,1])\n",
    "        cbar.set_ticklabels(['0','0.5','1'])\n",
    "        plt.show()\n",
    "        if epoch+1==epochs:\n",
    "            plt.savefig(save_text+'.pdf')\n",
    "    \n",
    "    # Now test on best val model\n",
    "    model = torch.load(best_model_path)\n",
    "    model.eval()\n",
    "    val_dice = 0\n",
    "    val_acc = 0\n",
    "    val_iou = 0\n",
    "    val_sensitivity = 0\n",
    "    val_specificity = 0\n",
    "    val_avg_loss=0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in test_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "            Y_pred = model(X_batch)\n",
    "            loss = criterion.get_loss(Y_pred,Y_batch)\n",
    "            test_avg_loss += loss / len(val_loader)\n",
    "            test_metrics = evaluator.get_metrics(F.sigmoid(Y_pred),Y_batch)\n",
    "            test_dice += test_metrics['dice']/ len(test_loader)\n",
    "            test_acc += test_metrics['acc']/ len(test_loader)\n",
    "            test_iou += test_metrics['iou']/ len(test_loader)\n",
    "            test_sensitivity += test_metrics['sensitivity']/ len(test_loader)\n",
    "            test_specificity += test_metrics['specificity']/ len(test_loader)\n",
    "\n",
    "    test_final_metrics = {'loss':test_avg_loss,'acc':test_acc,'dice':test_dice,'iou':test_iou,'sensitivity':test_sensitivity,'specificity':test_specificity}\n",
    "\n",
    "    Y_hat = F.sigmoid(model(X_test.to(device))).detach().cpu()    \n",
    "    fig, ax = plt.subplots(nrows=4, ncols=6, figsize=(8.5, 5),dpi=400)\n",
    "    for k in range(6):\n",
    "        im = np.rollaxis(X_val[k].numpy(), 0, 3)\n",
    "        cmap = 'jet'\n",
    "        ax[0,k].imshow(im)\n",
    "        ax[1,k].imshow(Y_test[k, 0], cmap=cmap)\n",
    "        ax[2,k].imshow(Y_hat[k, 0], cmap=cmap,vmin=0, vmax=1)\n",
    "        thres = 0.5\n",
    "        maskim = im.copy()\n",
    "        maskim[Y_hat[k][0]<=thres] = [0,0,0]\n",
    "        implt = ax[3,k].imshow(maskim, cmap=cmap,vmin=0, vmax=1)\n",
    "    titles = ['Real','Mask','Output','Threshold']\n",
    "    for i in range(4): \n",
    "        ax[i,0].text(-0.1, 0.5, titles[i],rotation=90,ha='center',va='center',transform=ax[i,0].transAxes)\n",
    "    for a in ax.flat: \n",
    "        a.set_axis_off()\n",
    "    #metricstxt = 'dice: {:.2f} iou: {:.2f} acc: {:.2f} sens: {:.2f} spec: {:.2f}'.format(val_dice,val_iou,val_acc,val_sensitivity,val_specificity)\n",
    "    #ax[0,0].text(0, 1.25, metricstxt,ha='left',va='center',transform=ax[0,0].transAxes)\n",
    "    plt.suptitle(f\"Test on best validation\")\n",
    "    metricstxt = f'Total epochs {epochs}    loss: {test_avg_loss:.2f}'\n",
    "    cbar = fig.colorbar(implt, ax=ax.ravel().tolist(), shrink=0.97)\n",
    "    cbar.set_ticks([0,thres,1])\n",
    "    cbar.set_ticklabels(['0','0.5','1'])\n",
    "    plt.show()\n",
    "    plt.savefig(save_text+'_test'+'.pdf')\n",
    "\n",
    "    return best_train_final_metrics,best_val_final_metrics,test_final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_type = 'BCE'\n",
    "criterion = criterion = loss_func(type_=loss_type) #torch.nn.BCEWithLogitsLoss()\n",
    "model = EncDec().to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "train_metrics,val_metrics,test_metrics = train(model=model,opt=optimizer,criterion=criterion,epochs=2,train_loader=train_loader,val_loader=val_loader,test_loader=test_loader,save_text=f\"EncDec_{loss_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics,val_metrics,test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = criterion = loss_func(type_='BCE') #torch.nn.BCEWithLogitsLoss()\n",
    "model = UNET().to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "train(model=model,opt=optimizer,criterion=criterion,epochs=50,train_loader=train_loader,val_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
